{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langsmith import expect\n",
    "# Installing necessary dependencies to run MCP\n",
    "!pip install arxiv python-dotenv anthropic\n",
    "# Installing the MCP sercer code\n",
    "!pip install \"mcp[cli]\""
   ],
   "id": "fff977091eebb858",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T00:19:46.991459Z",
     "start_time": "2025-06-22T00:19:46.986062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile research_server.py\n",
    "\n",
    "# reinstall as we are writing file in disk instead of running it in notebook\n",
    "!pip install arxiv python-dotenv anthropic\n",
    "# Installing the MCP sercer code\n",
    "!pip install \"mcp[cli]\"\n",
    "\n",
    "\n",
    "\n",
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n"
   ],
   "id": "9df7de428e233a00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting research_server.py\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T00:19:48.930636Z",
     "start_time": "2025-06-22T00:19:48.736881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAPER_DIR = \"papers\"\n",
    "mcp = FastMCP(\"research\")"
   ],
   "id": "3cd510dd80d964ff",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FastMCP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m PAPER_DIR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpapers\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m mcp \u001B[38;5;241m=\u001B[39m FastMCP(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresearch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'FastMCP' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the papers directory. The tool does not download the papers.",
   "id": "7c51e05023fc3cc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@mcp.tool()\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "    # Use arxiv to find the papers\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids\n",
    "\n",
    "@mcp.tool()\n",
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "\n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "\n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize and run the server\n",
    "    mcp.run(transport='stdio')"
   ],
   "id": "fe8a57a0326b887c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing the functionalities of search_paper by plugging in examples",
   "id": "36ee6a2881f20afc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supply_and_demand_papers = search_papers(\"supply and demand\")",
   "id": "4e82eb13eea3d4e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dd1d4cc53289730f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "extract_info(supply_and_demand_papers[1])",
   "id": "ad64753f8c4bb505",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Server Code All Together\n",
   "id": "ecfb0985b3fc883b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T00:20:53.905885Z",
     "start_time": "2025-06-22T00:20:53.899285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile research_server.py\n",
    "\n",
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "\n",
    "PAPER_DIR = \"papers\"\n",
    "\n",
    "# Initialize FastMCP server\n",
    "mcp = FastMCP(\"research\")\n",
    "\n",
    "@mcp.tool()\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "    # Use arxiv to find the papers\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids\n",
    "\n",
    "@mcp.tool()\n",
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "\n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "\n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize and run the server\n",
    "    mcp.run(transport='stdio')"
   ],
   "id": "69831781c3d80958",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting research_server.py\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
