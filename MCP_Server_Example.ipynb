{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langsmith import expect\n",
    "# Installing necessary dependencies to run MCP\n",
    "!pip install arxiv python-dotenv anthropic\n",
    "# Installing the MCP sercer code\n",
    "!pip install \"mcp[cli]\""
   ],
   "id": "fff977091eebb858",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T00:19:46.991459Z",
     "start_time": "2025-06-22T00:19:46.986062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile research_server.py\n",
    "\n",
    "# reinstall as we are writing file in disk instead of running it in notebook\n",
    "!pip install arxiv python-dotenv anthropic\n",
    "# Installing the MCP sercer code\n",
    "!pip install \"mcp[cli]\"\n",
    "\n",
    "\n",
    "\n",
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n"
   ],
   "id": "9df7de428e233a00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting research_server.py\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T00:19:48.930636Z",
     "start_time": "2025-06-22T00:19:48.736881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAPER_DIR = \"papers\"\n",
    "mcp = FastMCP(\"research\")"
   ],
   "id": "3cd510dd80d964ff",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FastMCP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m PAPER_DIR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpapers\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m mcp \u001B[38;5;241m=\u001B[39m FastMCP(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresearch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'FastMCP' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the papers directory. The tool does not download the papers.",
   "id": "7c51e05023fc3cc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@mcp.tool()\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "    # Use arxiv to find the papers\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids\n",
    "\n",
    "@mcp.tool()\n",
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "\n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "\n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize and run the server\n",
    "    mcp.run(transport='stdio')"
   ],
   "id": "fe8a57a0326b887c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing the functionalities of search_paper by plugging in examples",
   "id": "36ee6a2881f20afc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supply_and_demand_papers = search_papers(\"supply and demand\")",
   "id": "4e82eb13eea3d4e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dd1d4cc53289730f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "extract_info(supply_and_demand_papers[1])",
   "id": "ad64753f8c4bb505",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Server Code All Together\n",
   "id": "ecfb0985b3fc883b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T02:02:01.581726Z",
     "start_time": "2025-06-22T02:02:01.575633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile research_server.py\n",
    "\n",
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "\n",
    "PAPER_DIR = \"papers\"\n",
    "\n",
    "# Initialize FastMCP server\n",
    "mcp = FastMCP(\"research\")\n",
    "\n",
    "@mcp.tool()\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "    # Use arxiv to find the papers\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids\n",
    "\n",
    "@mcp.tool()\n",
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "\n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "\n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\"\n",
    "\n",
    "@mcp.resource(\"papers://folders\")\n",
    "def get_available_folders() -> str:\n",
    "    \"\"\"\n",
    "    List all available topic folders in the papers directory.\n",
    "\n",
    "    This resource provides a simple list of all available topic folders.\n",
    "    \"\"\"\n",
    "    folders = []\n",
    "\n",
    "    # Get all topic directories\n",
    "    if os.path.exists(PAPER_DIR):\n",
    "        for topic_dir in os.listdir(PAPER_DIR):\n",
    "            topic_path = os.path.join(PAPER_DIR, topic_dir)\n",
    "            if os.path.isdir(topic_path):\n",
    "                papers_file = os.path.join(topic_path, \"papers_info.json\")\n",
    "                if os.path.exists(papers_file):\n",
    "                    folders.append(topic_dir)\n",
    "\n",
    "    # Create a simple markdown list\n",
    "    content = \"# Available Topics\\n\\n\"\n",
    "    if folders:\n",
    "        for folder in folders:\n",
    "            content += f\"- {folder}\\n\"\n",
    "        content += f\"\\nUse @{folder} to access papers in that topic.\\n\"\n",
    "    else:\n",
    "        content += \"No topics found.\\n\"\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "@mcp.resource(\"papers://{topic}\")\n",
    "def get_topic_papers(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Get detailed information about papers on a specific topic.\n",
    "\n",
    "    Args:\n",
    "        topic: The research topic to retrieve papers for\n",
    "    \"\"\"\n",
    "    topic_dir = topic.lower().replace(\" \", \"_\")\n",
    "    papers_file = os.path.join(PAPER_DIR, topic_dir, \"papers_info.json\")\n",
    "\n",
    "    if not os.path.exists(papers_file):\n",
    "        return f\"# No papers found for topic: {topic}\\n\\nTry searching for papers on this topic first.\"\n",
    "\n",
    "    try:\n",
    "        with open(papers_file, 'r') as f:\n",
    "            papers_data = json.load(f)\n",
    "\n",
    "        # Create markdown content with paper details\n",
    "        content = f\"# Papers on {topic.replace('_', ' ').title()}\\n\\n\"\n",
    "        content += f\"Total papers: {len(papers_data)}\\n\\n\"\n",
    "\n",
    "        for paper_id, paper_info in papers_data.items():\n",
    "            content += f\"## {paper_info['title']}\\n\"\n",
    "            content += f\"- **Paper ID**: {paper_id}\\n\"\n",
    "            content += f\"- **Authors**: {', '.join(paper_info['authors'])}\\n\"\n",
    "            content += f\"- **Published**: {paper_info['published']}\\n\"\n",
    "            content += f\"- **PDF URL**: [{paper_info['pdf_url']}]({paper_info['pdf_url']})\\n\\n\"\n",
    "            content += f\"### Summary\\n{paper_info['summary'][:500]}...\\n\\n\"\n",
    "            content += \"---\\n\\n\"\n",
    "\n",
    "        return content\n",
    "    except json.JSONDecodeError:\n",
    "        return f\"# Error reading papers data for {topic}\\n\\nThe papers data file is corrupted.\"\n",
    "\n",
    "\n",
    "@mcp.prompt()\n",
    "def generate_search_prompt(topic: str, num_papers: int = 5) -> str:\n",
    "    \"\"\"Generate a prompt for Claude to find and discuss academic papers on a specific topic.\"\"\"\n",
    "    return f\"\"\"Search for {num_papers} academic papers about '{topic}' using the search_papers tool. Follow these instructions:\n",
    "    1. First, search for papers using search_papers(topic='{topic}', max_results={num_papers})\n",
    "    2. For each paper found, extract and organize the following information:\n",
    "       - Paper title\n",
    "       - Authors\n",
    "       - Publication date\n",
    "       - Brief summary of the key findings\n",
    "       - Main contributions or innovations\n",
    "       - Methodologies used\n",
    "       - Relevance to the topic '{topic}'\n",
    "\n",
    "    3. Provide a comprehensive summary that includes:\n",
    "       - Overview of the current state of research in '{topic}'\n",
    "       - Common themes and trends across the papers\n",
    "       - Key research gaps or areas for future investigation\n",
    "       - Most impactful or influential papers in this area\n",
    "\n",
    "    4. Organize your findings in a clear, structured format with headings and bullet points for easy readability.\n",
    "\n",
    "    Please present both detailed information about each paper and a high-level synthesis of the research landscape in {topic}.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize and run the server\n",
    "    mcp.run(transport='stdio')"
   ],
   "id": "69831781c3d80958",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting research_server.py\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
